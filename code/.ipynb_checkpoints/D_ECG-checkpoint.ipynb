{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2603a7c5-12ee-4aec-be15-234b8f7f558a",
   "metadata": {},
   "source": [
    "# Diagnosis based on ECG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9bd26-b72e-474e-a942-14d6b1ed5123",
   "metadata": {},
   "source": [
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd0dec-dfe7-42b9-ad33-b4a46524aaef",
   "metadata": {},
   "source": [
    "* Diagnosis using collected ECG data\n",
    "* Currently total 42 subjects\n",
    "* 3 classes (DEP, SUI, NOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25eea5-7d1f-401a-8134-ec7fbff1f678",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812ed44-f853-4ce4-8ce2-27146f72459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required components \n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3c86b-4a67-4726-9061-ab9fbc3d6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4ff95-374a-40cb-a65a-cf8cc591bb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9b688-f5bd-48dc-a605-f75e418ef0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40df9de8-0768-4084-b76d-e2a81676c9e1",
   "metadata": {},
   "source": [
    "## Basic data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25788be7-1aa1-4f8f-9d72-db7caf375b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df = pd.read_csv('E:/RESEARCH/Datasets/wearable/AI_coded_1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c563b2-1a0e-4890-8d18-b4afa99c19d6",
   "metadata": {},
   "source": [
    "* 1: depression, 2: suicidality, 3: normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce0f46-956b-4c1e-9a4f-a9b7f0468f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df['class'] = ecg_df['class'].astype(\"category\")\n",
    "ecg_df['sub'] = ecg_df['sub'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3417ed-fc23-4f4c-8218-2bb952701d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression = ecg_df[ecg_df['class']==1]\n",
    "print((depression.index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66cdb7-bc36-424c-a4fe-97e94228dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "suicidal = ecg_df[ecg_df['class']==2]\n",
    "print((suicidal.index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f283e0-3bf8-438e-b918-fd7e6466de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = ecg_df[ecg_df['class']==3]\n",
    "print((normal.index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cd5e2-caf8-456f-9f20-c260fb0955bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c770d8-588e-46ad-99e5-1347cb72334d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b7fa493-ab29-4e90-8743-2fccebc6fa60",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153cdc7-38a1-4dcf-b06f-c3b2f872a620",
   "metadata": {},
   "source": [
    "## Image Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a532aec-63f2-4f00-955d-a752c95171e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking file path and names\n",
    "file_path = \"E:/RESEARCH/Datasets/wearable/ECG/test_0420/train/dep/\"\n",
    "file_names = os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7300a5-dfa7-4809-bace-3cda6a9a6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing file names to 1, 2, ...\n",
    "i = 1\n",
    "for name in file_names:\n",
    "    src = os.path.join(file_path, name)\n",
    "    dst = str(i) + '.png'\n",
    "    dst = os.path.join(file_path, dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789ee5d-6ef2-4000-b80c-ab383bc1c5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Converting pdf file into png file\n",
    "for name in file_names:\n",
    "    pages = convert_from_path(file_path + name, poppler_path=\"E:/RESEARCH/Datasets/wearable/ECG/poppler/Library/bin\")\n",
    "    \n",
    "    for page in pages:\n",
    "        page.save(file_path + name + '.png', \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae611-4319-44ed-812d-b8623ebd4ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Data Crop (deleting patients' information)\n",
    "# original png size = 2200 x 1700\n",
    "# leaving the important part only (only the ecg data part)\n",
    "left = 100\n",
    "top = 450\n",
    "right = 2100\n",
    "bottom = 1300\n",
    "## 100, 450, 2100, 1300 스케일로 자르면 딱 ecg 30초 전체 부분 나옴.\n",
    "\n",
    "for name in file_names:\n",
    "    im = Image.open(file_path + name)\n",
    "    imc = im.crop((left, top, right, bottom))\n",
    "    imc.save(file_path+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527baf7-6b7e-41fa-b06c-3ca2abccf29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory setting and get file names for 2 second cycle of ECG\n",
    "crop_path = \"E:/RESEARCH/Datasets/wearable/ECG/test_0420/train_crop/sui/\"\n",
    "crop_names = os.listdir(crop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8336ff-97ad-4064-909b-5103d1e16fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the points for cropped image\n",
    "left = 1000\n",
    "top = 0\n",
    "right =1400\n",
    "bottom = 250\n",
    "## 위에서 한번 처리한 이미지에 대해 1000, 0, 1400, 250로 자르면 딱 5~7초 ecg cycle 나옴.\n",
    "\n",
    "\n",
    "for name in crop_names:\n",
    "    im = Image.open(crop_path + name)\n",
    "    imc = im.crop((left, top, right, bottom))\n",
    "    imc.save(crop_path+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907379e-8027-4dbd-a2cc-4588f0c02ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing file names to 1, 2, ...\n",
    "i = 1\n",
    "for name in crop_names:\n",
    "    src = os.path.join(crop_path, name)\n",
    "    dst = str(i) + '.png'\n",
    "    dst = os.path.join(crop_path, dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37414a-601e-4d7c-9ecc-8678e5e0f2a4",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356055b6-cff6-4b08-99d6-8049f1e83305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf86b83-a7bd-43ed-8da7-2e247cdbb17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53c89b-6157-4245-a27d-e793b2cefb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956d57c-5e30-44cc-a5b9-39cfc97c86ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957f4a-40b0-4192-9aa3-6457cf7ac32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70db10d-aca4-4343-a171-8a22f391226d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf83414-2198-47a4-b366-590a6117a63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141238f-7cf6-4341-9b76-4a55bbcf8f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc927db1-35c3-4235-984c-94757dd92dd7",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5079a1-9dd5-43f6-8058-d7eda91cfbf8",
   "metadata": {},
   "source": [
    "## With simple image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8936ca-fda9-41e7-a24e-4422a03dc8bd",
   "metadata": {},
   "source": [
    "* Our dataset numbers (dep: 244, nor: 402, sui: 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce99b05-e36a-4827-ad61-df08aca02a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=50\n",
    "    bs=16\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    num_channels=3 \n",
    "    num_classes=3\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70151a5a-f25e-4e82-b6d2-d35c01b5c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4417cf1-5a8f-4103-8191-983c78afcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_res = models.resnet18(num_classes=2, pretrained=True)\n",
    "model_eff3 = EfficientNet.from_pretrained('efficientnet-b3', num_classes=args.num_classes)\n",
    "# model_resnet18 = models.resnet18(pretrained=True)\n",
    "# model_mobnetv2 = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01ca93-b1fd-4463-91d0-89dcabfdfb61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_mobnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce0c5d-56df-4872-abdb-bfcac48ca6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## resnet 구조는 마지막 fc layer의 out_features 를 바꿔주면 되고.\n",
    "model_resnet18.fc = nn.Linear(in_features = 512, out_features = args.num_classes)\n",
    "# model_mobnetv2.classifier = nn.Linear(in_features = 512, out_features = args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed26f5c-43a4-4bb3-9357-2f8b5699f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_res.to(DEVICE)\n",
    "model = model_eff3.to(DEVICE)\n",
    "# model = model_mobnetv2.to(DEVICE)\n",
    "# model = model_resnet18.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0c466-ca78-4b73-a00e-31479aa7aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239a6a8-7d4d-4687-982e-be64ce036fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe02e6d-7faa-4416-8f70-78d6cfb71456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(256),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(contrast=(0.3, 1), saturation=(0.3, 1)),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456,0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5f590-3361-4b96-9a7a-f0899f25131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897fb805-20c1-49ed-a895-b47f4c2e25e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75f98b-fe76-43c3-8bce-cb81e9456ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading image data\n",
    "# ecg_data = datasets.ImageFolder(root = 'E:/RESEARCH/Datasets/wearable/ECG/test_0420/train', transform = data_transforms)\n",
    "ecg_data = datasets.ImageFolder(root = 'E:/RESEARCH/Datasets/wearable/ECG/test_0420/train_crop', transform = data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9f889-526a-4b06-95e5-365972a4ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(ecg_data))\n",
    "test_size = len(ecg_data)-train_size\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753f461-3468-4dbb-ad3b-6af7edc72ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(ecg_data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436a011-6965-4f17-a6fe-e204b9906e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef1ca4-e3c8-487e-b02d-844947b9845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7aacc-663c-45a6-b5a1-e07e9bfe88c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353cb358-d690-4705-b373-40ba7e952110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c87af-3007-4797-8e73-9adf7d132ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Optimizer and Objective Function\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, total_steps=50, anneal_strategy='cos')\n",
    "criterion = nn.CrossEntropyLoss() ## setup the loss function\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537645c2-462f-4570-b2ba-997e0034e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))\n",
    "\n",
    "    scheduler.step() #for learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba0939-a6eb-437e-b2cf-fbab13373ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    validation =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "    \n",
    "    test_loss /= (len(test_loader)) \n",
    "    validation_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    validation.append(validation_accuracy)\n",
    "    \n",
    "    return test_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee0e44-78b0-41a4-838a-7b390275e29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904fcda-c97a-4626-9b9b-74e297552492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "\n",
    "total = []\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, validation_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tValidation Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, validation_accuracy))\n",
    "    \n",
    "    total.append((test_loss, validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa96dc-44bb-4da2-874f-c76d1894da6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b4a56-a74b-4229-9a5f-392e7265fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_classes = args.num_classes\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "classes = {\n",
    "    \"0\": \"Depression\",\n",
    "    \"1\": \"Normal\",\n",
    "    \"2\": \"Suicidality\"\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (image, label) in enumerate(test_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "print(confusion_matrix)\n",
    "\n",
    "class_names = list(classes.values())\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=8)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=8)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('dep_train_entire_output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c30c1-92df-4722-a55b-de66a440b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix\n",
    "total = sum(sum(cm))\n",
    "\n",
    "## Accuracy, Sensitivity, and Specificity\n",
    "acc = (cm[0,0]+cm[1,1]+cm[2,2]) / total\n",
    "sen_dep = cm[0,0] / (cm[0,0] + cm[0,1] + cm[0,2])\n",
    "sen_nor = cm[1,1] / (cm[1,0] + cm[1,1] + cm[1,2])\n",
    "sen_sui = cm[2,2] / (cm[2,0] + cm[2,1] + cm[2,2])\n",
    "\n",
    "spe_dep = (cm[1,1] + cm[2,2]) / (cm[1,0] + cm[2,0] + cm[1,1] + cm[2,2])\n",
    "spe_nor = (cm[0,0] + cm[2,2]) / (cm[0,1] + cm[2,1] + cm[0,0] + cm[2,2])\n",
    "spe_sui = (cm[0,0] + cm[1,1]) / (cm[0,2] + cm[1,2] + cm[0,0] + cm[1,1])\n",
    "\n",
    "print(\"Overall classification accuracy is :\", round(acc, 4))\n",
    "print(\"sensitivity of depression class is :\", round(sen_dep, 4))\n",
    "print(\"sensitivity of normal class is :\", round(sen_nor,4))\n",
    "print(\"sensitivity of suicidal class is :\", round(sen_sui,4))\n",
    "\n",
    "print(\"specificity of depression class is :\", round(spe_dep,4))\n",
    "print(\"specificity of normal class is :\", round(spe_nor,4))\n",
    "print(\"specificity of suicidal class is :\", round(spe_sui,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d65d4-6abb-44c0-b950-96dcb34d2735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfda23b-db79-46ae-a588-a9cb662616cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c254a3-41f5-448e-8dcf-49f379115096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3107cadd-99bc-4c85-aacb-139f651786a4",
   "metadata": {},
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da136b-3d2a-45c8-bc88-406bdfd19385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c59a7c-a279-4f1a-ab12-47fb5404db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimator = model,\n",
    "    n_estimators = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1aa59-f6ab-4713-a31f-078c91665271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Set the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "ensemble.set_criterion(criterion)\n",
    "ensemble.set_optimizer(\n",
    "    \"Adam\", lr = args.lr\n",
    ")\n",
    "\n",
    "ensemble.set_scheduler(\n",
    "    \"CosineAnnealingLR\", T_max=args.epochs\n",
    ")\n",
    "\n",
    "# Train the ensemble\n",
    "ensemble.fit(\n",
    "    train_loader, epochs=args.epochs\n",
    ")\n",
    "\n",
    "# Evaluate the ensemble\n",
    "acc = ensemble.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c76bc-a50b-49de-b70e-50426d2ed909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b94425-fbc8-43aa-8054-1761b4c35d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff891a-2efe-427e-b7bc-c5823bf74714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053666d7-2496-4dd2-aa6e-6b9152826a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc83e5a-5034-4aa0-b9eb-1587be9f8350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c5c39-5ce8-4b17-a1d3-e0dcd4f2b8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5ad07-4f53-445e-89d1-511410ddbfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2844fe8-1f20-41e4-9021-983d25038c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e692c-f3e8-4053-b9bf-2635bd855fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4cfae-1ccd-40cf-a16c-6f247113c76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921df3d-af02-445d-bd45-98f56ee598c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862ba4f-8787-4241-b4a5-bb9f7fdd72d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54703c-82f9-4925-b887-b4b693ab38d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3dc8b-61ce-425c-b0ee-5b8695f1491d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6be033-c1d6-4602-b88e-84accab1268c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5ea26-b16d-4bba-877f-2f7a1023def8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e488d3-2084-4990-94f3-9175bb3b9804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687c0ba-b09e-414c-bc65-a79e7c38b187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92456f7-2340-4737-bf9e-cd12668cf593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
