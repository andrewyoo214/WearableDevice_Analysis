{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2603a7c5-12ee-4aec-be15-234b8f7f558a",
   "metadata": {},
   "source": [
    "# Diagnosis based on ECG data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9bd26-b72e-474e-a942-14d6b1ed5123",
   "metadata": {},
   "source": [
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd0dec-dfe7-42b9-ad33-b4a46524aaef",
   "metadata": {},
   "source": [
    "* Diagnosis using collected ECG data\n",
    "* Currently total 42 subjects\n",
    "* 3 classes (DEP, SUI, NOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25eea5-7d1f-401a-8134-ec7fbff1f678",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812ed44-f853-4ce4-8ce2-27146f72459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required components \n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3c86b-4a67-4726-9061-ab9fbc3d6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4ff95-374a-40cb-a65a-cf8cc591bb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9b688-f5bd-48dc-a605-f75e418ef0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40df9de8-0768-4084-b76d-e2a81676c9e1",
   "metadata": {},
   "source": [
    "## Basic data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25788be7-1aa1-4f8f-9d72-db7caf375b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df = pd.read_csv('E:/RESEARCH/Datasets/wearable/AI_coded_1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c563b2-1a0e-4890-8d18-b4afa99c19d6",
   "metadata": {},
   "source": [
    "* 1: depression, 2: suicidality, 3: normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce0f46-956b-4c1e-9a4f-a9b7f0468f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df['class'] = ecg_df['class'].astype(\"category\")\n",
    "ecg_df['sub'] = ecg_df['sub'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3417ed-fc23-4f4c-8218-2bb952701d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression = ecg_df[ecg_df['class']==1]\n",
    "print((depression.index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66cdb7-bc36-424c-a4fe-97e94228dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "suicidal = ecg_df[ecg_df['class']==2]\n",
    "print((suicidal.index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f283e0-3bf8-438e-b918-fd7e6466de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = ecg_df[ecg_df['class']==3]\n",
    "print((normal.index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09cd5e2-caf8-456f-9f20-c260fb0955bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c770d8-588e-46ad-99e5-1347cb72334d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b7fa493-ab29-4e90-8743-2fccebc6fa60",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153cdc7-38a1-4dcf-b06f-c3b2f872a620",
   "metadata": {},
   "source": [
    "* Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a532aec-63f2-4f00-955d-a752c95171e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking file path and names\n",
    "file_path = \"E:/RESEARCH/Datasets/wearable/ECG/test_0420/dep/\"\n",
    "file_names = os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7300a5-dfa7-4809-bace-3cda6a9a6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing file names to 1, 2, ...\n",
    "i = 1\n",
    "for name in file_names:\n",
    "    src = os.path.join(file_path, name)\n",
    "    dst = str(i) + '.png'\n",
    "    dst = os.path.join(file_path, dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789ee5d-6ef2-4000-b80c-ab383bc1c5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Converting pdf file into png file\n",
    "for name in file_names:\n",
    "    pages = convert_from_path(file_path + name, poppler_path=\"E:/RESEARCH/Datasets/wearable/ECG/poppler/Library/bin\")\n",
    "    \n",
    "    for page in pages:\n",
    "        page.save(file_path + name + '.png', \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae611-4319-44ed-812d-b8623ebd4ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Data Crop (deleting patients' information)\n",
    "# original png size = 2200 x 1700\n",
    "# leaving the important part only (only the ecg data part)\n",
    "left = 100\n",
    "top = 450\n",
    "right = 2100\n",
    "bottom = 1300\n",
    "\n",
    "for name in file_names:\n",
    "    im = Image.open(file_path + name)\n",
    "    imc = im.crop((left, top, right, bottom))\n",
    "    imc.save(file_path+name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37414a-601e-4d7c-9ecc-8678e5e0f2a4",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356055b6-cff6-4b08-99d6-8049f1e83305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf86b83-a7bd-43ed-8da7-2e247cdbb17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057d346-a560-4fee-bb67-e692f8a83123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5079a1-9dd5-43f6-8058-d7eda91cfbf8",
   "metadata": {},
   "source": [
    "## With simple image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8936ca-fda9-41e7-a24e-4422a03dc8bd",
   "metadata": {},
   "source": [
    "* Our dataset numbers (dep: 244, nor: 402, sui: 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce99b05-e36a-4827-ad61-df08aca02a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=8\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    num_channels=3 \n",
    "    num_classes=3\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70151a5a-f25e-4e82-b6d2-d35c01b5c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4417cf1-5a8f-4103-8191-983c78afcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_res = models.resnet18(num_classes=2, pretrained=True)\n",
    "# model_eff3 = EfficientNet.from_pretrained('efficientnet-b3', num_classes=args.num_classes)\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "# model_mobnetv2 = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce0c5d-56df-4872-abdb-bfcac48ca6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## resnet 구조는 마지막 fc layer의 out_features 를 바꿔주면 되고.\n",
    "# model_resnet18.fc = nn.Linear(in_features = 512, out_features = args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed26f5c-43a4-4bb3-9357-2f8b5699f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_res.to(DEVICE)\n",
    "# model = model_eff3.to(DEVICE)\n",
    "# model = model_mobnetv2.to(DEVICE)\n",
    "model = model_resnet18.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe02e6d-7faa-4416-8f70-78d6cfb71456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(contrast=(0.3, 1), saturation=(0.3, 1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456,0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5f590-3361-4b96-9a7a-f0899f25131a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897fb805-20c1-49ed-a895-b47f4c2e25e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75f98b-fe76-43c3-8bce-cb81e9456ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading image data\n",
    "ecg_data = datasets.ImageFolder(root = 'E:/RESEARCH/Datasets/wearable/ECG/test_0420/train',\n",
    "                                transform = data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9f889-526a-4b06-95e5-365972a4ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(ecg_Data))\n",
    "test_size = len(ecg_Data)-train_size\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753f461-3468-4dbb-ad3b-6af7edc72ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(ecg_data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436a011-6965-4f17-a6fe-e204b9906e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef1ca4-e3c8-487e-b02d-844947b9845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7aacc-663c-45a6-b5a1-e07e9bfe88c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353cb358-d690-4705-b373-40ba7e952110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c87af-3007-4797-8e73-9adf7d132ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Optimizer and Objective Function\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, total_steps=30, anneal_strategy='cos')\n",
    "criterion = nn.CrossEntropyLoss() ## setup the loss function\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537645c2-462f-4570-b2ba-997e0034e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))\n",
    "\n",
    "    scheduler.step() #for learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba0939-a6eb-437e-b2cf-fbab13373ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    validation =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader)) \n",
    "    validation_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    validation.append(validation_accuracy)\n",
    "    \n",
    "    return test_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904fcda-c97a-4626-9b9b-74e297552492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "\n",
    "total = []\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, validation_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tValidation Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, validation_accuracy))\n",
    "    \n",
    "    total.append((test_loss, validation_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa96dc-44bb-4da2-874f-c76d1894da6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec75e0-6ec0-4631-9f3c-89d9700105b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692ec56-f6b3-40ae-9947-f2f80ab7624a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862ba4f-8787-4241-b4a5-bb9f7fdd72d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54703c-82f9-4925-b887-b4b693ab38d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3dc8b-61ce-425c-b0ee-5b8695f1491d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6be033-c1d6-4602-b88e-84accab1268c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5ea26-b16d-4bba-877f-2f7a1023def8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e488d3-2084-4990-94f3-9175bb3b9804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687c0ba-b09e-414c-bc65-a79e7c38b187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92456f7-2340-4737-bf9e-cd12668cf593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
